{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:07:26.399267Z",
     "start_time": "2019-06-08T02:07:26.338860Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:34:20.719696Z",
     "start_time": "2019-06-08T02:34:19.119053Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from helpers import *\n",
    "import urllib\n",
    "from visdom import Visdom\n",
    "from torch._jit_internal import weak_module,weak_script_method\n",
    "import matplotlib.pyplot as plt\n",
    "#viz = Visdom(env='Testouiles')\n",
    "#from torch.nn.backends.backend.j import weak_module, weak_script_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:09:38.316717Z",
     "start_time": "2019-06-06T21:09:38.293617Z"
    }
   },
   "outputs": [],
   "source": [
    "@weak_module\n",
    "class SpatialPyramidPooling(nn.Module) :\n",
    "    def __init__(self,pyramid_levels=3) : \n",
    "        super(SpatialPyramidPooling,self).__init__()\n",
    "        self.pyramid = [nn.AdaptiveMaxPool2d(output_size=(1,1))]\n",
    "        for i in range(1,pyramid_levels) : \n",
    "            self.pyramid.append(nn.AdaptiveMaxPool2d(output_size=(i*2,i*2)))\n",
    "        \n",
    "    @weak_script_method\n",
    "    def forward(self,input) :\n",
    "        cat = []\n",
    "        for p in self.pyramid : \n",
    "            cat.append(p(input).view(input.size(0),-1))\n",
    "        return torch.cat(cat,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:35:08.607817Z",
     "start_time": "2019-06-08T02:35:08.409417Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders, dataset_sizes, device,class_names,image_datasets = load_datas('/home/etienne/Desktop/Data-Shark/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:35:15.270453Z",
     "start_time": "2019-06-08T02:35:09.556913Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloaders))\n",
    "batch_gpu = batch[0].to(device)\n",
    "#viz.images(unormalize_batch(batch_gpu,mean,std),win='expample images',opts=dict(title='Shark images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:30:56.986784Z",
     "start_time": "2019-06-06T21:30:55.710873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n"
     ]
    }
   ],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "vgg16.features[-1] = SpatialPyramidPooling() # Spatial pooling pyramid level 3\n",
    "classifier = nn.Sequential(nn.Linear(10752,2048,bias=True),nn.ReLU(),nn.Linear(2048,1),nn.Sigmoid())\n",
    "shark_detector = nn.Sequential(vgg16.features,classifier)\n",
    "shark_detector.to(device)\n",
    "print('Model Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:34:27.907151Z",
     "start_time": "2019-06-08T02:34:25.054795Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:36:27.333555Z",
     "start_time": "2019-06-08T02:36:27.055812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:36:43.534791Z",
     "start_time": "2019-06-08T02:36:43.458372Z"
    }
   },
   "outputs": [],
   "source": [
    "t = vgg16.features(batch_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T02:36:47.811516Z",
     "start_time": "2019-06-08T02:36:47.766344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 7, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:31:02.771878Z",
     "start_time": "2019-06-06T21:31:02.128602Z"
    }
   },
   "outputs": [],
   "source": [
    "t = shark_detector(batch_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:31:03.585916Z",
     "start_time": "2019-06-06T21:31:03.559018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4564],\n",
       "        [0.4699],\n",
       "        [0.4401],\n",
       "        [0.4429],\n",
       "        [0.4463],\n",
       "        [0.4643],\n",
       "        [0.4724],\n",
       "        [0.4879],\n",
       "        [0.4920],\n",
       "        [0.4562]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View imagenet Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:38:40.904093Z",
     "start_time": "2019-05-05T19:38:40.478546Z"
    }
   },
   "outputs": [],
   "source": [
    "class_imagenet = pickle.load(urllib.request.urlopen('https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:39:28.823556Z",
     "start_time": "2019-05-05T19:39:28.789529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hammerhead 10.220370292663574',\n",
       " 'hammerhead 9.88038158416748',\n",
       " 'hammerhead 9.702723503112793',\n",
       " 'hammerhead 9.298279762268066',\n",
       " 'hammerhead 10.194511413574219',\n",
       " 'hammerhead 10.02170467376709',\n",
       " 'scuba diver 8.803277969360352',\n",
       " 'scuba diver 10.63332748413086',\n",
       " 'hammerhead 8.901375770568848',\n",
       " 'hammerhead 8.357734680175781']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preds = ['{} {}'.format(class_imagenet[x.item()].split(',')[0],p) for p,x in list(zip(list(predictions.max(dim=1))[0],list(predictions.max(dim=1))[1]))]\n",
    "text_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ImageNet)",
   "language": "python",
   "name": "pycharm-3d8a7761"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
