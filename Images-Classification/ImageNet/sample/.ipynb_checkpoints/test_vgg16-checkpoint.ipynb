{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:11.458261Z",
     "start_time": "2019-05-06T05:36:11.445083Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:12.732290Z",
     "start_time": "2019-05-06T05:36:12.182146Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from helpers import *\n",
    "import urllib\n",
    "from visdom import Visdom\n",
    "from torch._jit_internal import weak_module,weak_script_method\n",
    "import matplotlib.pyplot as plt\n",
    "#viz = Visdom(env='Testouiles')\n",
    "#from torch.nn.backends.backend.j import weak_module, weak_script_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:13.701132Z",
     "start_time": "2019-05-06T05:36:13.684533Z"
    }
   },
   "outputs": [],
   "source": [
    "@weak_module\n",
    "class SpatialPyramidPooling(nn.Module) :\n",
    "    def __init__(self,pyramid_levels=3) : \n",
    "        super(SpatialPyramidPooling,self).__init__()\n",
    "        self.pyramid = [nn.AdaptiveMaxPool2d(output_size=(1,1))]\n",
    "        for i in range(1,pyramid_levels) : \n",
    "            self.pyramid.append(nn.AdaptiveMaxPool2d(output_size=(i*2,i*2)))\n",
    "        \n",
    "    @weak_script_method\n",
    "    def forward(self,input) :\n",
    "        cat = []\n",
    "        for p in self.pyramid : \n",
    "            cat.append(p(input).view(input.size(0),-1))\n",
    "        return torch.cat(cat,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:14.740734Z",
     "start_time": "2019-05-06T05:36:14.708197Z"
    },
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders, dataset_sizes, device,class_names,image_datasets = load_datas('../bruvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:36:18.639073Z",
     "start_time": "2019-05-06T05:36:15.757954Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloaders))\n",
    "batch_gpu = batch[0].to(device)\n",
    "#viz.images(unormalize_batch(batch_gpu,mean,std),win='expample images',opts=dict(title='Shark images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:44:53.584822Z",
     "start_time": "2019-05-06T05:44:52.298104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): SpatialPyramidPooling()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=10752, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "vgg16.features[-1] = SpatialPyramidPooling()\n",
    "classifier = nn.Sequential(nn.Linear(10752,2048,bias=True),nn.ReLU(),nn.Linear(2048,1),nn.Sigmoid())\n",
    "shark_detector = nn.Sequential(vgg16.features,classifier)\n",
    "shark_detector.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:44:56.905151Z",
     "start_time": "2019-05-06T05:44:56.873443Z"
    }
   },
   "outputs": [],
   "source": [
    "t = shark_detector(batch_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T05:44:59.921882Z",
     "start_time": "2019-05-06T05:44:59.892828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5123],\n",
       "        [0.4945],\n",
       "        [0.5315],\n",
       "        [0.5150],\n",
       "        [0.5171],\n",
       "        [0.4840],\n",
       "        [0.5244],\n",
       "        [0.5151],\n",
       "        [0.5087],\n",
       "        [0.5106]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# View imagenet Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:38:40.904093Z",
     "start_time": "2019-05-05T19:38:40.478546Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class_imagenet = pickle.load(urllib.request.urlopen('https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:39:28.823556Z",
     "start_time": "2019-05-05T19:39:28.789529Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hammerhead 10.220370292663574',\n",
       " 'hammerhead 9.88038158416748',\n",
       " 'hammerhead 9.702723503112793',\n",
       " 'hammerhead 9.298279762268066',\n",
       " 'hammerhead 10.194511413574219',\n",
       " 'hammerhead 10.02170467376709',\n",
       " 'scuba diver 8.803277969360352',\n",
       " 'scuba diver 10.63332748413086',\n",
       " 'hammerhead 8.901375770568848',\n",
       " 'hammerhead 8.357734680175781']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preds = ['{} {}'.format(class_imagenet[x.item()].split(',')[0],p) for p,x in list(zip(list(predictions.max(dim=1))[0],list(predictions.max(dim=1))[1]))]\n",
    "text_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ImageNet)",
   "language": "python",
   "name": "pycharm-3d8a7761"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
